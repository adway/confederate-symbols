print("hello")
install.packages('censusapi')
Sys.setenv(CENSUS_KEY=6825eedc40f186b604694ba8be85c2c6d0a3d559)
Sys.setenv(CENSUS_KEY = "6825eedc40f186b604694ba8be85c2c6d0a3d559")
readRenviron("~/.Renviron")
Sys.getenv("CENSUS_KEY")
library(censusapi)
mycensuskey = "6825eedc40f186b604694ba8be85c2c6d0a3d559"
availableVars <- listCensusMetadata(name = "acs1", vintage = 2015)
View(availableVars)
View(availableVars)
write.csv(availableVars, file = "available_vars.csv", row.names = FALSE)
write.csv(availableVars, file = "available_vars.csv", row.names = FALSE)
install.packages(tidyverse)
install.packages('tidyverse')
library("tidyverse", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("cluster", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages('factoextra')
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
df <- USArrests
View(df)
View(df)
df <- na.omit(df)
df <- scale(df)
View(df)
View(df)
View(df)
View(df)
head(df)
print('Ask Jesus')
distance <- get_dist(df)
distance
fviz_dist(distance, gradient = list(low = "#e509ae", mid = "#aa08e5", high = "#07e507"))
install.packages()
install.packages('clustertend')
library(clustertend) # Measures the tendency of a dataset to cluster, by computing the hopkins statistic.
hopkins(df, n = nrow(df)-1)
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
source('~/Machine_Learning/usa_arrests.R')
fviz_dist(distance, gradient = list(low = "#e509ae", mid = "#FFFFFF", high = "#07e507"))
k2 <- kmeans(df, centers = 2, nstart = 25)
str(k2)
fviz_cluster(k2, data = df)
k2 <- kmeans(df, centers = 2, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
# Optimal number of clusters
set.seed(123)
wss <- function(k) {
kmeans(df, k, nstart = 10 )$tot.withinss
}
k.values <- 1:15
# Run function for various K values
wss_values <- map_dbl(k.values, wss)
# Plot elbow curve
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
# Optimal number of clusters
set.seed(123)
fviz_nbclust(df, kmeans, method = "wss")
# Optimal number of clusters
set.seed(123)
fviz_nbclust(df, kmeans, method = "wss")
fviz_nbclust(df, kmeans, method = "silhouette")
setwd('~/machine_learning/confederate')
# Load Packages
library(dplyr)
library(ggplot2)
library(mapdata)
library(ggmap)
setwd('~/machine_learning/confederate')
data <- read.csv('confederate_symbols.csv')
data <- data[-c(1100), ]
groupedByState <- group_by(data, data$state)
summarizedState <- summarize(groupedByState, count = n())
summarizedState <- summarizedState[!(summarizedState$`data$state`=="1913"),]
# Sort
summarizedState <- summarizedState[order(summarizedState$count, decreasing = TRUE),]
# Bar Plot
barplot(summarizedState$count, names.arg = summarizedState$`data$state`, las = 2)
# GROUP BY TYPE
groupedByType <- group_by(data, data$category)
summarizedType <- summarize(groupedByType, count = n())
#Sort
summarizedType <- summarizedType[order(summarizedType$count, decreasing = TRUE),]
#Plot
barplot(summarizedType$count, names.arg = summarizedType$`data$category`, las = 2)
## VIS ON MAP
states <- map_data("state")
map <- ggplot()
map <- map + geom_polygon(data=states, aes(x=long, y=lat, group = group),colour="#a50104")
map <- map + geom_point(data=data, aes(x=longitude, y=latitude), color="white")
map
# Census API -- Population of State
pop <- read.csv('PEP_2017_PEPANNRES_with_ann.csv')
groupedPopByState <- group_by(pop, pop$GEO.display.label)
groupedPopByState <- groupedPopByState[7:57,]
groupedPopByState <- groupedPopByState[!(groupedPopByState$GEO.display.label=='District of Columbia'),]
stateCount <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
statePop <- data.frame(groupedPopByState$GEO.display.label, groupedPopByState$respop72017)
per100K <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
for(i in 1:1480) {
for(j in 1:50) {
if(toString(groupedByState$state[i]) == toString(stateCount$groupedPopByState.GEO.display.label[j])){
stateCount$numeric.50.[j] <- stateCount$numeric.50.[j] + 1
}
}
}
View(per100K)
View(per100K)
View(stateCount)
View(stateCount)
View(statePop)
View(statePop)
View(stateCount)
View(stateCount)
stateCount <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
statePop <- data.frame(groupedPopByState$GEO.display.label, groupedPopByState$respop72017)
percapita <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
View(percapita)
View(percapita)
percapita$numeric.50. <- stateCount$numeric.50./statePop$groupedPopByState.respop72017
View(df)
View(df)
View(per100K)
View(per100K)
pop <- read.csv('PEP_2017_PEPANNRES_with_ann.csv')
groupedPopByState <- group_by(pop, pop$GEO.display.label)
groupedPopByState <- groupedPopByState[7:57,]
groupedPopByState <- groupedPopByState[!(groupedPopByState$GEO.display.label=='District of Columbia'),]
stateCount <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
statePop <- data.frame(groupedPopByState$GEO.display.label, groupedPopByState$respop72017)
percapita <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
for(i in 1:1480) {
for(j in 1:50) {
if(toString(groupedByState$state[i]) == toString(stateCount$groupedPopByState.GEO.display.label[j])){
stateCount$numeric.50.[j] <- stateCount$numeric.50.[j] + 1
}
}
}
stateCount$numeric.50. <- as.numeric(stateCount$numeric.50.)
statePop$groupedPopByState.respop72017 <- as.numeric(statePop$groupedPopByState.respop72017)
percapita$numeric.50. <- stateCount$numeric.50./statePop$groupedPopByState.respop72017
View(per100K)
# Census API -- Population of State
pop <- read.csv('PEP_2017_PEPANNRES_with_ann.csv')
groupedPopByState <- group_by(pop, pop$GEO.display.label)
groupedPopByState <- groupedPopByState[7:57,]
groupedPopByState <- groupedPopByState[!(groupedPopByState$GEO.display.label=='District of Columbia'),]
stateCount <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
statePop <- data.frame(groupedPopByState$GEO.display.label, groupedPopByState$respop72017)
percapita <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
for(i in 1:1480) {
for(j in 1:50) {
if(toString(groupedByState$state[i]) == toString(stateCount$groupedPopByState.GEO.display.label[j])){
stateCount$numeric.50.[j] <- stateCount$numeric.50.[j] + 1
}
}
}
percapita$numeric.50.[,3] <- stateCount$numeric.50.[,2]/statePop$groupedPopByState.respop72017[,2]
View(stateCount)
View(stateCount)
percapita$numeric.50.[,2] <- stateCount$numeric.50.[,2]/statePop$groupedPopByState.respop72017[,2]
percapita[,2] <- stateCount[,2]/statePop$groupedPopByState[,2]
View(percapita)
View(percapita)
# Census API -- Population of State
pop <- read.csv('PEP_2017_PEPANNRES_with_ann.csv')
groupedPopByState <- group_by(pop, pop$GEO.display.label)
groupedPopByState <- groupedPopByState[7:57,]
groupedPopByState <- groupedPopByState[!(groupedPopByState$GEO.display.label=='District of Columbia'),]
stateCount <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
statePop <- data.frame(groupedPopByState$GEO.display.label, groupedPopByState$respop72017)
percapita <- data.frame(groupedPopByState$GEO.display.label, numeric(50))
for(i in 1:1480) {
for(j in 1:50) {
if(toString(groupedByState$state[i]) == toString(stateCount$groupedPopByState.GEO.display.label[j])){
stateCount$numeric.50.[j] <- stateCount$numeric.50.[j] + 1
}
}
}
percapita[,2] <- stateCount[,2]/statePop$groupedPopByState[,2]
View(per100K)
View(percapita)
View(percapita)
stateCount[1,2]/statePop$groupedPopByState[1,2]
